# HW5 Web搜索引擎  

作业要求：

> 实现本次作业主要有⽹⻚抓取、文本索引、链接分析、查询服务、个性化查询⼏个步骤，个性化推荐为扩展内容



本次作业自起始阶段就发布在[WangshuXC/Search_engine](https://github.com/WangshuXC/Search_engine)



## 网页抓取

### 抓取内容

本人抓取的网页为`https://www.gushici.com/`，抓取的内容为网页上所有的诗、词、曲、文言文

以一个抓取到的内容为例来展示每个具体项：

```json
  {
    "id": 53,
    "url": "https://www.gushici.com/t_53",
    "title": "赠汪伦",
    "auth": "李白",
    "auth_id": 618,
    "auth_intro": "李白（701年－762年），字太白，号青莲居士，唐朝浪漫主义诗人，被后人誉为“诗仙”。祖籍陇西成纪(待考)，出生于西域碎叶城，4岁再随父迁至剑南道绵州。李白存世诗文千余篇，有《李太白集》传世。762年病逝，享年61岁。其墓在今安徽当涂，四川江油、湖北安陆有纪念馆。",
    "dynasty": "唐代",
    "type": "诗",
    "body": "<p>李白乘舟将欲行，忽闻岸上踏歌声。</p><p>桃花潭水深千尺，不及汪伦送我情。</p>",
    "translation": "<p>我正乘上小船，刚要解缆出发，忽听岸上传来，悠扬踏歌之声。</p><p>看那桃花潭水，纵然深有千尺，怎能及汪伦送我之情。</p><div><p>参考资料：</p><p>1、张国举．唐诗精华注译评．唐诗：唐诗精华注译评，2010：185-186</p></div>",
    "explanation": "<p>踏歌：唐代一作广为流行的民间歌舞形式，一边唱歌，一边用脚踏地打拍子，可以边走边唱。</p><p>桃花潭：在今安徽泾县西南一百里。《一统志》谓其深不可测。深千尺：诗人用潭水深千尺比喻汪伦与他的友情，运用了夸张的手法（潭深千尺不是实有其事）。不及：不如。</p>",
    "appreciation": "<p>　　用比兴手法，表达了对汪伦深情相送的感激。用“深千尺”的潭水比喻送别之深情，生动而形象，而又加“不及”二字，更增强了诗句的动人力量。这首有明显的民歌风味的诗词自然质朴，清新流畅。诗人用眼前普通的景物作比喻，写出了与友人的真挚情意。</p>",
    "related": [
      "https://www.gushici.com/t_46",
      "https://www.gushici.com/t_100",
      "https://www.gushici.com/t_116",
      "https://www.gushici.com/t_159",
      "https://www.gushici.com/t_166",
      "https://www.gushici.com/t_273",
      "https://www.gushici.com/t_862051",
      "https://www.gushici.com/t_1192921"
    ]
  }
```



### 抓取思路

首先进入到该网站的诗、词、曲、文言文目录页面，即`https://www.gushici.com/p_p_1`到`https://www.gushici.com/p_p_4`

然后分析网页结构，很容易发现该网站的目录页面的页数切换是通过请求api然后动态加载来实现的。

随后自然而然地找到该请求api，发现其格式为`https://www.gushici.com/poetry_list?type={type}&page={page}`，{type}处应填入`诗、词、曲、文言文`其中一项，{page}则为页数。例如我想查询诗目录的第114页，则向`https://www.gushici.com/poetry_list?type=诗&page=114`发送请求。

上述api的返回值是一个json，通过解析、存储这个json，就能轻易地获取到网页的数据。



但是有一个问题，为了后续的**链接分析**过程，还需要找到一些相互关联的网站。为了解决这个问题，我来到了古诗的详情页，以[《赠汪伦》](https://www.gushici.com/t_53)这首诗为例，不难发现其页面中有一个*”猜你喜欢“*板块，这个板块能够链接到其他古诗的详情页，基于此我们就可以抓取相关网页链接来进行链接分析。

![image-20231211190022809](./assets/image-20231211190022809.png)



### 爬虫代码

相关部分在`spider.py`的`spider_index()`和`spider_link(url)`两个函数



代码的运行流程大致如下：

1. 导入所需的库和模块。
2. 定义`spider_index()`函数，用于爬取首页数据。该函数内部定义了一个内部函数`process_page()`，用于处理每一页的数据。`process_page()`函数接收参数url（首页URL）、type（类型，如诗、词、曲等）和num_pages（总页数），并返回一个包含所有数据的列表。
3. 在`spider_index()`函数中，通过不同的URL调用`process_page()`函数，分别爬取诗、词、曲和文言文的数据，并将所有数据合并到`data_list`列表中。
4. 将爬取到的数据写入文件"data.json"中。
5. 定义`spider_link()`函数，用于爬取诗词详情页的链接。该函数使用BeautifulSoup解析网页并获取链接，返回一个包含链接的列表。
6. 使用`retry`装饰器修饰`spider_link()`函数，设置重试次数为3次，每次重试之间的延迟为10秒。

7. 在`if __name__ == "__main__":`语句块中，首先检查是否已经存在"data.json"文件，如果存在则直接跳过爬取步骤，否则调用`spider_index()`函数进行初次爬取。



## 文本索引



